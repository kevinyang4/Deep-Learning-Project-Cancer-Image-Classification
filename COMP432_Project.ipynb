{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "import os\n",
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time\n",
        "import cv2\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Function\n",
        "from sklearn.manifold import TSNE\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import models\n",
        "from torchvision import datasets, transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import classification_report, accuracy_score, silhouette_score\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn.cluster import KMeans\n"
      ],
      "metadata": {
        "id": "Ru49h5UjAD-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1"
      ],
      "metadata": {
        "id": "CV-2he3aAAWp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IHk5G5KCcPgl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "167c1c30-0d5e-49a2-edfd-e2741db03d88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "# check if GPU is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# unzip folder\n",
        "!unzip -q \"Dataset 1.zip\" -d \"/content\""
      ],
      "metadata": {
        "collapsed": true,
        "id": "hkGotaYN__zi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a13c356-acf8-4fd5-89aa-b1f1547b5d65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open Dataset 1.zip, Dataset 1.zip.zip or Dataset 1.zip.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "WY4s1uWTM7LF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "85929220-7b3f-43b0-f95e-ce1f5fe5554c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    135\u001b[0m   )\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define data transforms for augmentation and normalization\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load the dataset using ImageFolder\n",
        "data_dir = '/content/Dataset 1/Colorectal Cancer '\n",
        "medical_dataset = datasets.ImageFolder(root=data_dir, transform=data_transforms)\n",
        "\n",
        "# Split dataset into 70% training and 30% testing sets\n",
        "train_size = int(0.6 * len(medical_dataset))\n",
        "val_size = int(0.2 * len(medical_dataset))\n",
        "test_size = len(medical_dataset) - train_size - val_size\n",
        "train_set, val_set, test_set = random_split(medical_dataset, [train_size, val_size, test_size])\n",
        "\n",
        "# Create DataLoaders for training, validation, and test sets\n",
        "train_loader = DataLoader(train_set, batch_size=32, shuffle=True, num_workers=4)\n",
        "val_loader = DataLoader(val_set, batch_size=32, shuffle=False, num_workers=4)\n",
        "test_loader = DataLoader(test_set, batch_size=32, shuffle=False, num_workers=4)\n",
        "\n",
        "class_names = medical_dataset.classes  # ['MUS', 'NORM', 'STR']"
      ],
      "metadata": {
        "id": "6k2am6C1BcGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a ResNet18 model\n",
        "model = models.resnet18(pretrained=False)\n",
        "\n",
        "# Replace the final layer to match the number of classes (3: MUS, NORM, STR)\n",
        "num_features = model.fc.in_features\n",
        "model.fc = nn.Linear(num_features, 3)  # 3 output classes\n",
        "\n",
        "# Move model to GPU if available\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "x-XyXWDTCKWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "xkurdxFdCx0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, val_loader, optimizer, criterion, num_epochs):\n",
        "    best_model_wts = None\n",
        "    best_val_acc = 0.0\n",
        "    train_losses, val_losses = [], []\n",
        "    train_accuracies, val_accuracies = [], []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        running_loss, correct, total = 0.0, 0, 0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        train_loss = running_loss / len(train_loader)\n",
        "        train_acc = 100 * correct / total\n",
        "        train_losses.append(train_loss)\n",
        "        train_accuracies.append(train_acc)\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_loss, correct, total = 0.0, 0, 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                val_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "        val_acc = 100 * correct / total\n",
        "        val_losses.append(val_loss)\n",
        "        val_accuracies.append(val_acc)\n",
        "\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            best_model_wts = model.state_dict()\n",
        "\n",
        "        print(f\"Epoch [{epoch + 1}/{num_epochs}] \"\n",
        "              f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.2f}% \"\n",
        "              f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_acc:.2f}%\")\n",
        "\n",
        "    # Load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, train_losses, train_accuracies, val_losses, val_accuracies"
      ],
      "metadata": {
        "id": "nQc2nJiOC0Ym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model\n",
        "_, loss_list, accuracy_list, _, _ = train_model(model, train_loader, val_loader, optimizer, criterion, num_epochs=10)"
      ],
      "metadata": {
        "id": "5krmwU13hgmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the loss and accuracy over epochs\n",
        "epochs = range(1, len(loss_list) + 1)\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "\n",
        "# plot loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, loss_list, '-o', label='Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss vs. Epochs')\n",
        "plt.legend()\n",
        "\n",
        "# plot accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, accuracy_list, '-o', label='Accuracy', color='green')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy vs. Epochs')\n",
        "plt.legend()\n",
        "\n",
        "# display the plots\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "svHd6iOwhkvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_names = ['MUS', 'NORM', 'STR']\n",
        "\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "\n",
        "\n",
        "    if target_names is not None:\n",
        "        print(\"Classification Report:\")\n",
        "        print(classification_report(all_labels, all_preds, target_names=target_names, zero_division=0))\n",
        "    else:\n",
        "        print(\"Classification Report:\")\n",
        "        print(classification_report(all_labels, all_preds, zero_division=0))\n",
        "\n",
        "    print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "gq_n1G6qhrI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluate the model\n",
        "evaluate_model(model, test_loader)"
      ],
      "metadata": {
        "id": "xoMmuGcNiGkn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(model, dataloader):\n",
        "    model.eval()\n",
        "    features = []\n",
        "    labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, label in dataloader:\n",
        "            inputs = inputs.to(device)\n",
        "            output = model(inputs)  # Extract features from the final FC layer\n",
        "            features.append(output.cpu().numpy())\n",
        "            labels.extend(label.numpy())\n",
        "\n",
        "    return np.concatenate(features), np.array(labels)\n",
        "\n",
        "# Extract features from the test set\n",
        "features, labels = extract_features(model, test_loader)\n",
        "\n",
        "# Apply t-SNE for dimensionality reduction\n",
        "tsne = TSNE(n_components=2, random_state=42)\n",
        "features_2d = tsne.fit_transform(features)\n",
        "\n",
        "# Get the Silhouette score\n",
        "kmeans = KMeans(n_clusters=len(np.unique(labels)), random_state=42)\n",
        "kmeans_labels = kmeans.fit_predict(features)\n",
        "\n",
        "sil_score = silhouette_score(features, kmeans_labels)\n",
        "print(f\"Silhouette Score: {sil_score}\")\n",
        "\n",
        "# Plot the t-SNE result\n",
        "def plot_tsne(features, labels, class_names, title=\"t-SNE of CNN Features\"):\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    for class_id, class_name in enumerate(class_names):\n",
        "        idx = labels == class_id\n",
        "        plt.scatter(features[idx, 0], features[idx, 1], label=class_name, alpha=0.7)\n",
        "    plt.legend()\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "plot_tsne(features_2d, labels, class_names)\n"
      ],
      "metadata": {
        "id": "OnsJbhr8C2M5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Map\n",
        "class FeatureExtractor:\n",
        "    def __init__(self, model, layer_name):\n",
        "        self.model = model\n",
        "        self.layer_name = layer_name\n",
        "        self.feature_map = None\n",
        "        self.hook = self._register_hook()\n",
        "\n",
        "    def _register_hook(self):\n",
        "        layer = dict(self.model.named_modules())[self.layer_name]\n",
        "        hook = layer.register_forward_hook(self._hook_fn)\n",
        "        return hook\n",
        "\n",
        "    def _hook_fn(self, module, input, output):\n",
        "        self.feature_map = output.detach()\n",
        "\n",
        "    def remove_hook(self):\n",
        "        self.hook.remove()\n",
        "\n",
        "    def get_feature_map(self):\n",
        "        return self.feature_map\n",
        "\n",
        "\n",
        "# Grad-CAM Class\n",
        "class GradCAM:\n",
        "    def __init__(self, model, target_layer):\n",
        "        self.model = model\n",
        "        self.target_layer = target_layer\n",
        "        self.gradients = None\n",
        "        self.feature_maps = None\n",
        "\n",
        "        self.feature_extractor = FeatureExtractor(model, target_layer)\n",
        "        self.target_layer = dict(model.named_modules())[target_layer]\n",
        "        self.target_layer.register_backward_hook(self._save_gradients)\n",
        "\n",
        "    def _save_gradients(self, module, grad_input, grad_output):\n",
        "        self.gradients = grad_output[0]\n",
        "\n",
        "    def forward(self, input_image):\n",
        "        return self.model(input_image)\n",
        "\n",
        "    def generate_cam(self, input_image, class_idx=None):\n",
        "        # Forward pass\n",
        "        self.model.zero_grad()\n",
        "        output = self.forward(input_image)\n",
        "        if class_idx is None:\n",
        "            class_idx = torch.argmax(output)\n",
        "\n",
        "        # Backward pass\n",
        "        self.model.zero_grad()\n",
        "        output[:, class_idx].backward()\n",
        "\n",
        "        # Get the feature maps and gradients\n",
        "        feature_maps = self.feature_extractor.get_feature_map()\n",
        "        gradients = self.gradients\n",
        "\n",
        "        # Compute the weights for each feature map\n",
        "        weights = torch.mean(gradients, dim=(2, 3), keepdim=True)\n",
        "        cam = torch.sum(weights * feature_maps, dim=1, keepdim=True)\n",
        "        cam = F.relu(cam)\n",
        "        cam = cam.squeeze().cpu().detach().numpy()\n",
        "\n",
        "        # Normalize the CAM to [0, 1]\n",
        "        cam = cv2.resize(cam, (input_image.shape[3], input_image.shape[2]))\n",
        "        cam = (cam - np.min(cam)) / (np.max(cam) - np.min(cam))\n",
        "\n",
        "        return cam\n",
        "\n",
        "\n",
        "# Overlay CAM on Image and Save\n",
        "def overlay_cam_on_image(original_image, cam, save_path, alpha=0.5):\n",
        "    # Convert CAM to BGR and resize\n",
        "    cam = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)\n",
        "    cam = cv2.cvtColor(cam, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Convert original image to numpy and normalize it to [0, 255]\n",
        "    original_image = original_image.squeeze().permute(1, 2, 0).cpu().numpy()\n",
        "    original_image = (original_image * 255).astype(np.uint8)  # Convert to uint8\n",
        "\n",
        "    # Overlay the CAM on the image\n",
        "    overlayed_image = cv2.addWeighted(original_image, alpha, cam, 1 - alpha, 0)\n",
        "\n",
        "    # Save the overlayed image\n",
        "    plt.imsave(save_path, overlayed_image)\n",
        "    print(f\"Saved Grad-CAM image to: {save_path}\")\n",
        "\n",
        "\n",
        "\n",
        "# Visualize and Save Grad-CAMs for All Batches\n",
        "def visualize_and_save_gradcam_all_batches(model, test_loader, target_layer='layer4', device='cuda', save_dir='gradcam_outputs'):\n",
        "    model.eval() #Set the model to evaluation mode\n",
        "    os.makedirs(save_dir, exist_ok=True)  # Create directory if it doesn't exist\n",
        "\n",
        "    grad_cam = GradCAM(model, target_layer)\n",
        "\n",
        "    for batch_idx, (inputs, labels) in enumerate(test_loader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # Loop over each image in the batch\n",
        "        for i in range(inputs.size(0)):\n",
        "            input_image = inputs[i].unsqueeze(0)\n",
        "            cam = grad_cam.generate_cam(input_image)\n",
        "\n",
        "            # Define the save path for each image\n",
        "            save_path = os.path.join(save_dir, f\"batch_{batch_idx}_image_{i}_true_{labels[i].item()}_pred_{torch.argmax(model(inputs[i].unsqueeze(0))).item()}.png\")\n",
        "\n",
        "            # Save CAM overlayed image\n",
        "            overlay_cam_on_image(inputs[i], cam, save_path)\n",
        "\n",
        "            # Optionally print the label and predicted class for logging\n",
        "            print(f\"Batch {batch_idx} - True label: {labels[i].item()} - Predicted label: {torch.argmax(model(inputs[i].unsqueeze(0))).item()}\")\n",
        "\n",
        "\n",
        "# Example Usage\n",
        "# Assuming `model` and `test_loader` are already defined and `device` is either 'cuda' or 'cpu'.\n",
        "visualize_and_save_gradcam_all_batches(model, test_loader, target_layer='layer4', device='cuda', save_dir='gradcam_outputs')\n"
      ],
      "metadata": {
        "id": "0FprjFyuNmBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating different hyperparameters"
      ],
      "metadata": {
        "id": "RePxg0Oi9Njr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate hyperparameters of the model\n",
        "from itertools import product\n",
        "\n",
        "# Hyperparameter tuning\n",
        "learning_rates = [0.1, 0.01, 0.001, 0.0001]\n",
        "batch_sizes = [8, 16, 32, 64]\n",
        "num_epochs = 10\n",
        "best_params = {}\n",
        "best_val_acc = 0.0\n",
        "\n",
        "for lr, batch_size in product(learning_rates, batch_sizes):\n",
        "    print(f\"Testing Hyperparameters: LR={lr}, Batch Size={batch_size}\")\n",
        "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "    val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "    # Initialize model, loss, and optimizer\n",
        "    model = models.resnet18(pretrained=False)\n",
        "    num_features = model.fc.in_features\n",
        "    model.fc = nn.Linear(num_features, len(medical_dataset.classes))  # Adjust output layer for 3 classes\n",
        "    model = model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    # Train and evaluate model\n",
        "    model, _, _, _, val_accuracies = train_model(model, train_loader, val_loader, optimizer, criterion, num_epochs)\n",
        "    max_val_acc = max(val_accuracies)\n",
        "\n",
        "    if max_val_acc > best_val_acc:\n",
        "        best_val_acc = max_val_acc\n",
        "        best_params = {'learning_rate': lr, 'batch_size': batch_size}\n",
        "\n",
        "print(f\"Best Hyperparameters: {best_params}, Best Validation Accuracy: {best_val_acc:.2f}%\")\n"
      ],
      "metadata": {
        "id": "QzizSFp0Nw-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 2"
      ],
      "metadata": {
        "id": "Q_Lb_3WTSJYb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use model trained on Colorectal cancer"
      ],
      "metadata": {
        "id": "axCAMLqAe-cf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# unzip folder\n",
        "!unzip -q \"Dataset 2.zip\" -d \"/content\""
      ],
      "metadata": {
        "id": "-d5qcYERrTVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# unzip folder\n",
        "!unzip -q \"Dataset 3.zip\" -d \"/content\""
      ],
      "metadata": {
        "id": "eHyFVQeYrVdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove the classification head from the Task 1 model\n",
        "encoder_task1 = torch.nn.Sequential(*list(model.children())[:-1])  # Remove the final layer\n",
        "encoder_task1.eval()  # Set to evaluation mode"
      ],
      "metadata": {
        "id": "_CxMwEqkdQfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the encoder\n",
        "torch.save(encoder_task1, 'task1_encoder.pth')\n",
        "\n",
        "# Reload if needed\n",
        "encoder_task1 = torch.load('task1_encoder.pth')\n",
        "encoder_task1.eval()"
      ],
      "metadata": {
        "id": "cacy09o5fDbG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transforms (same as Task 1 for consistency)\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load datasets\n",
        "data_dir2 = '/content/Dataset 2/Prostate Cancer'\n",
        "data_dir3 = '/content/Dataset 3/Animal Faces'\n",
        "\n",
        "dataset2 = datasets.ImageFolder(root=data_dir2, transform=data_transforms)\n",
        "dataset3 = datasets.ImageFolder(root=data_dir3, transform=data_transforms)\n",
        "\n",
        "dataloader2 = DataLoader(dataset2, batch_size=32, shuffle=False)\n",
        "dataloader3 = DataLoader(dataset3, batch_size=32, shuffle=False)\n"
      ],
      "metadata": {
        "id": "iewA9Dy1gHZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract features for Dataset 2\n",
        "features2_task1, labels2_task1 = extract_features(encoder_task1, dataloader2)\n",
        "\n",
        "# Extract features for Dataset 3\n",
        "features3_task1, labels3_task1 = extract_features(encoder_task1, dataloader3)\n"
      ],
      "metadata": {
        "id": "esMGnGiGgb83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load ImageNet-pretrained encoder (e.g., ResNet-18)\n",
        "imagenet_encoder = models.resnet18(pretrained=True)\n",
        "imagenet_encoder = torch.nn.Sequential(*list(imagenet_encoder.children())[:-1])\n",
        "imagenet_encoder.eval()\n",
        "\n",
        "# Extract features for Dataset 2\n",
        "features2_imagenet, labels2_imagenet = extract_features(imagenet_encoder, dataloader2)\n",
        "\n",
        "# Extract features for Dataset 3\n",
        "features3_imagenet, labels3_imagenet = extract_features(imagenet_encoder, dataloader3)\n"
      ],
      "metadata": {
        "id": "tXV-Ooypgvkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 1 Encoder on Dataset 2\n",
        "features2_task1_tsne = np.squeeze(tsne.fit_transform(np.squeeze(features2_task1), labels2_task1))\n",
        "plot_tsne(features2_task1_tsne, labels2_task1, dataset2.classes)\n",
        "\n",
        "# Task 1 Encoder on Dataset 3\n",
        "features3_task1_tsne = tsne.fit_transform(np.squeeze(features3_task1), labels3_task1)\n",
        "plot_tsne(features3_task1_tsne, labels3_task1, dataset3.classes)\n",
        "\n",
        "# ImageNet Encoder on Dataset 2\n",
        "features2_imagenet_tsne = tsne.fit_transform(np.squeeze(features2_imagenet), labels2_imagenet)\n",
        "plot_tsne(features2_imagenet_tsne, labels2_imagenet, dataset2.classes)\n",
        "\n",
        "# ImageNet Encoder on Dataset 3\n",
        "features3_imagenet_tsne = tsne.fit_transform(np.squeeze(features3_imagenet), labels3_imagenet)\n",
        "plot_tsne(features3_imagenet_tsne, labels3_imagenet, dataset3.classes)\n"
      ],
      "metadata": {
        "id": "dll_2xtIgwkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Classification of Dataset Using a Machine Learning Technique (SVM)</h1>"
      ],
      "metadata": {
        "id": "XkR4qSJI1jZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Dataset 2: Using features extracted by Task 1 encoder\n",
        "X2 = features2_task1_2d\n",
        "y2 = labels2_task1_2d\n",
        "\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the SVM classifier\n",
        "svm_clf = SVC(kernel='linear', random_state=42)\n",
        "svm_clf.fit(X2_train, y2_train)\n",
        "\n",
        "# Make predictions\n",
        "y2_pred = svm_clf.predict(X2_test)\n",
        "\n",
        "X2_tsne = tsne.fit_transform(X2_test, y2_test)\n",
        "plot_tsne(X2_tsne, y2_pred, dataset2.classes)\n",
        "\n",
        "\n",
        "# Evaluate the performance\n",
        "print(\"Dataset 2 (Task 1 Encoder) - SVM Results\")\n",
        "print(\"Accuracy:\", accuracy_score(y2_test, y2_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y2_test, y2_pred))\n",
        "# Dataset 3: Using features extracted by Task 1 encoder\n",
        "X3 = np.squeeze(features3_task1)\n",
        "y3 = np.squeeze(labels3_task1)\n",
        "# Split data into training and testing sets\n",
        "X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the SVM classifier\n",
        "svm_clf = SVC(kernel='linear', random_state=42)\n",
        "svm_clf.fit(X3_train, y3_train)\n",
        "\n",
        "# Make predictions\n",
        "y3_pred = svm_clf.predict(X3_test)\n",
        "\n",
        "X3_tsne = tsne.fit_transform(X3_test, y3_test)\n",
        "plot_tsne(X3_tsne, y3_pred, dataset2.classes)\n",
        "\n",
        "# Evaluate the performance\n",
        "print(\"Dataset 3 (Task 1 Encoder) - SVM Results\")\n",
        "print(\"Accuracy:\", accuracy_score(y3_test, y3_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y3_test, y3_pred))"
      ],
      "metadata": {
        "id": "swrR-8YW1eJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset 2: Using features extracted by ImageNet encoder\n",
        "X2 = np.squeeze(features2_imagenet)\n",
        "y2 = np.squeeze(labels2_imagenet)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the SVM classifier\n",
        "svm_clf = SVC(kernel='linear', random_state=42)\n",
        "svm_clf.fit(X2_train, y2_train)\n",
        "\n",
        "# Make predictions\n",
        "y2_pred = svm_clf.predict(X2_test)\n",
        "\n",
        "X2_tsne = tsne.fit_transform(X2_test, y2_test)\n",
        "plot_tsne(X2_tsne, y2_pred, dataset2.classes)\n",
        "\n",
        "# Evaluate the performance\n",
        "print(\"Dataset 2 (ImageNet Encoder) - SVM Results\")\n",
        "print(\"Accuracy:\", accuracy_score(y2_test, y2_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y2_test, y2_pred))\n",
        "\n",
        "# Dataset 3: Using features extracted by ImageNet encoder\n",
        "X3 = np.squeeze(features3_imagenet)\n",
        "y3 = np.squeeze(labels3_imagenet)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the SVM classifier\n",
        "svm_clf = SVC(kernel='linear', random_state=42)\n",
        "svm_clf.fit(X3_train, y3_train)\n",
        "\n",
        "# Make predictions\n",
        "y3_pred = svm_clf.predict(X3_test)\n",
        "\n",
        "X3_tsne = tsne.fit_transform(X3_test, y3_test)\n",
        "plot_tsne(X3_tsne, y3_pred, dataset2.classes)\n",
        "\n",
        "# Evaluate the performance\n",
        "print(\"Dataset 3 (ImageNet Encoder) - SVM Results\")\n",
        "print(\"Accuracy:\", accuracy_score(y3_test, y3_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y3_test, y3_pred))"
      ],
      "metadata": {
        "id": "--mVvtNf1fjv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}